
<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Weijian (William) Luo</title>
<meta name="description" content="Weijian Luo's academic website.">

<!-- Open Graph --> 


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="main.css">

<link rel="canonical" href="/">

<!-- Theming-->


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="row ml-1 ml-sm-0">
          <span class="contact-icon text-center">
  <a href="mailto:pkulwj1994@icloud.com"><i class="fas fa-envelope"></i></a>
  <a href="https://scholar.google.com/citations?hl=zh-CN&user=kAYjIR4AAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>  
  <a href="https://github.com/pkulwj1994" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<!--   <a href="https://www.linkedin.com/in/xxx/" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
<!--   <a href="https://twitter.com/xxx" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a> -->
  
  
  
  
</span>

        </div>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="index.html">
              About
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>

          <li class="nav-item ">
              <a class="nav-link" href="publications.html">
                Publications
                
              </a>
          </li>

          <li class="nav-item ">
              <a class="nav-link" href="CV.pdf">
                CV                
              </a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Weijian Luo</span>
    </h1>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="./photos/me_new.png">
      
      
    </div>
    

    <div class="clearfix">
      <p> I am a final year PhD student at the School of Mathematical Sciences, <a href="http://english.pku.edu.cn">Peking University</a>. Prior to that, I received my M.S. Degree from the School of Mathematical Sciences, <a href="http://english.pku.edu.cn">Peking University</a>, and a B.S. degree in Statistics from <a href="https://www.ustc.edu.cn/">USTC</a> in China. My research interests focus on <a href="https://arxiv.org/abs/2304.04262"><b>diffusion distillation</b></a>. and <b>human-preference alignment</b>, as well as <b>large vision-language foundation models</b>. Currently, I am invited as a reviewer for academic journals including <b>Nature Communications</b> <a href="https://www.nature.com/ncomms/">(NC)</a>, IF: 14.7, IEEE <b>Transactions on Image Processing</b> <a href="https://signalprocessingsociety.org/publications-resources/ieee-transactions-image-processing">(TIP)</a>, IF: 10.8, IEEE <b>Transactions on Neural Networks and Learning Systems</b> <a href="https://cis.ieee.org/publications/t-neural-networks-and-learning-systems">(TNNLS)</a>, IF: 14.25, and <b>Pattern Recognition</b> <a href="https://www.sciencedirect.com/journal/pattern-recognition">(PR)</a>,  IF: 7.5. I also review for top AI Conferences including <b>NeurIPS, ICML, ICLR, AISTATS, UAI, ACM-MM, etc</b>;</p> 
      <p> <strong>Contact:</strong> <span style="font-family:'Lucida Console', monospace">pkulwj1994 at icloud dot com</span> 

<p><strong>News:</strong></p>

<ul>

  <li><strong>18th Oct 2024:</strong> one reprint released on Arxiv.<br>
    <strong>One-step Flow Matching Generators</strong> <a href="" target="\_blank">(Huang et al., 2024)</a>.<br>
    <em>We introduce a novel method to distill the flow-matching-based Stable Diffusion 3 model into strong one-step generators.</em>
  </li>

  <li><strong>18th Oct 2024:</strong> one reprint released on Arxiv.<br>
    <strong>Diff-Instruct*: Towards Human-Preferred One-step Text-to-image Generative Models</strong> <a href="" target="\_blank">(Luo et al., 2024)</a>.<br>
    <em>This paper introduces the <b>Diff-Instruct*</b>, a novel approach to train human-preferred large-scale one-step text-to-image generative models through the lens of online RLHF with general score-based constraints. The resulting one-step 0.6B DiT-DI* model achieves a SoTA <a href="https://github.com/tgxs002/HPSv2" target="\_blank">HPSv2.0</a> score of <b>28.70</b>.</em>
  </li>

  <li><strong>17th Oct 2024:</strong> one reprint released on Arxiv.<br>
    <strong>Diff-Instruct++: Training One-step Text-to-image Generator Model to Align with Human Preferences</strong> <a href="" target="\_blank">(Luo, 2024)</a>.<br>
    <em>This paper introduces the <b>Diff-Instruct++</b>, the first attempt at human preference alignment of large-scale one-step text-to-image generative models. The aligned one-step 0.6B DiT-DI++ model achieves a leading <a href="https://github.com/tgxs002/HPSv2" target="\_blank">HPSv2.0</a> score of <b>28.48</b>.</em>
  </li>
  
  <li><strong>14th Oct 2024:</strong>I passed the PhD defense in 14th Oct in <a href="http://english.pku.edu.cn">Peking University</a>. I feel humbled and grateful to be loved and helped by great advisors, family, and awesome friends.</li>
  
  <li><strong>26th Sep 2024:</strong> one paper accepted by <b>NeurIPS 2024</b>.<br>
    <strong>One-step Diffusion Distillation Through Score Implicit Matching</strong> <a href="https://nips.cc/virtual/2024/poster/93608" target="\_blank">(Luo et al., NeurIPS 2024)</a>.<br>
    <em>We introduce the score implicit matching, a novel one-step diffusion distillation approach with an amazing one-step text-to-image generative model. Appreciation to Prof. Zico Kolter and Prof. Guojun Qi.</em>
  </li>

  <li><strong>20th Jun 2024:</strong> one preprint released on <b>arXiv</b>.<br>
      <strong>Consistency Models Made Easy</strong> <a href="https://arxiv.org/abs/2406.14548" target="_blank">(Geng et al., 2024)</a>.<br>
      <em>We introduce a set of practical techniques for efficient training of consistency models, together with a comprehensive study on the Scaling Law of consistency models.</em>
  </li>

  <li><strong>24th Apr 2024:</strong> one paper accepted by <b>ICML 2024</b>.<br>
      <strong>Variational Schrödinger Diffusion Models</strong> <a href="https://openreview.net/forum?id=kRv0WPJd00" target="_blank">(Deng et al., ICML 2024)</a>.<br>
      <em>We introduce an efficient simulation-free Schrödinger diffusion model, with wide applications for image and time-series generation. Congratulations to Yixin and Dr. Deng.</em>
  </li>

  <li><strong>26th Sep 2023:</strong> one paper accepted by <b>NeurIPS 2023</b>.<br>
      <strong>Diff-instruct: A Universal Approach for Transferring Knowledge from Pre-trained Diffusion Models</strong> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/f115f619b62833aadc5acb058975b0e6-Abstract-Conference.html" target="_blank">(Luo et al., NeurIPS 2023)</a>.<br>
      <em>Diff-Instruct is a one-step diffusion distillation approach through the lens of distribution matching, with applications on text-to-3D generation and improving GAN generators.</em>
  </li>

  <li><strong>26th Sep 2023:</strong> one paper accepted by <b>NeurIPS 2023</b>.<br>
      <strong>Entropy-based Training Methods for Scalable Neural Implicit Samplers</strong> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/1646e34971facbcda3727d1dc28ab635-Abstract-Conference.html" target="_blank">(Luo et al., NeurIPS 2023)</a>.<br>
      <em>We introduced two interesting training approaches for neural implicit samplers termed KL and Fisher training.</em>
  </li>

  <li><strong>26th Sep 2023:</strong> one paper accepted by <b>NeurIPS 2023</b>.<br>
      <strong>SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models</strong> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/f4a6806490d31216a3ba667eb240c897-Abstract-Conference.html" target="_blank">(Xue et al., NeurIPS 2023)</a>.<br>
      <em>We introduced a novel diffusion sampler based on the Stochastic Adam theory, integrated for PixelArt-alpha diffusion models.</em>
  </li>

  <li><strong>26th Sep 2023:</strong> one paper accepted by <b>NeurIPS 2023</b>.<br>
      <strong>Enhancing Adversarial Robustness via Score-based Optimization</strong> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/a2e707354da36956945dbb288efe82b3-Abstract-Conference.html" target="_blank">(Zhang et al., NeurIPS 2023)</a>.<br>
      <em>We introduced a novel optimization-based adversarial defense based on pre-trained diffusion models.</em>
  </li>

  <li><strong>9th Apr 2023:</strong> one paper released on <b>arXiv</b>.<br>
      <strong>A Comprehensive Survey on Knowledge Distillation of Diffusion Models</strong> <a href="https://arxiv.org/abs/2304.04262" target="_blank">(Luo, 2023)</a>.<br>
      <em>The first survey on diffusion distillation and knowledge transferring of diffusion models.</em>
  </li>
</ul>

  
  
<!--       I am in the job market for the position of AIGC experts! </p>        
 -->
      
<!-- <p><strong> Research Areas:</strong> </p>
<p>Generative Modeling, Diffusion Models, Energy-Based Models, Statistical Sampling</p>

<p><strong> Lectures and Talks:</strong> </p>
<p><a href="http://www.cmstatistics.org/CMStatistics2022/index.php">Diffusion Contrastive Divergence@CMStatistics 2022 hybrid conference</a></p>      
<p><a href="https://www.math.pku.edu.cn/kxyj/xsbg/tlb/informationsciences/134567.htm">解读AI技术的应用进展</a></p>
<p><a href="https://www.math.pku.edu.cn/kxyj/xsbg/tlb/informationsciences/142129.htm">An introduction to Diffusion Probabilistic Models (DPM)</a></p>
<p><a href="https://www.math.pku.edu.cn/kxyj/xsbg/tlb/informationsciences/131427.htm">Recent Progress on Generative Modeling</a></p>
       -->
      
<!-- <p><strong> Sevices:</strong> </p> -->
<!-- <p>Reviewers: ICML, ICLR, AISTAT, UAI, AAAI.</p> -->
<!-- <p><strong> Softwares or Toolkits:</strong> </p> -->

<!-- <p><strong>Selected Publications (* indicates equal contribution or corresponding author):</strong></p>
<ul>

  <li><strong>Denoising Fisher Training For Neural Implicit Samplers</strong><be>
      <b>Weijian Luo</b>, Wei Deng<br>
      <em>preprint</em>, 2024</li>

  <li><strong>One-step Flow Matching Generators</strong><br>
      Zemin Huang, Zhengyang Geng, <b>Weijian Luo*</b>, Guo-Jun Qi<br>
      <em>preprint</em>, 2024</li>

  <li><strong>Diff-Instruct*: Towards Human-Preferred One-step Text-to-image Generative Models</strong><be>
      <b>Weijian Luo</b>, Colin zhang, Debing Zhang, Zhengyang Geng<br>
      <em>preprint</em>, 2024</li>
  
  <li><strong>One-Step Diffusion Distillation through Score Implicit Matching</strong><be>
      <b>Weijian Luo</b>, Zemin Huang, Zhengyang Geng, J Zico Kolter, Guo-Jun Qi<br>
      <em>Advances in Neural Information Processing Systems 37</em>, 2024</li>
  
  <li><strong>Diff-Instruct++: Training One-step Text-to-image Generator Model to Align with Human Preferences</strong><br>
      <b>Weijian Luo</b><br>
      <em>preprint</em>, 2024</li>
  
  <li><strong>Integrating Amortized Inference with Diffusion Models for Learning Clean Distribution from Corrupted Images</strong><br>
      Yifei Wang, Weimin Bai, <b>Weijian Luo</b>, Wenzheng Chen, He Sun<br>
      <em>arXiv preprint</em>, arXiv:2407.11162, 2024</li>

  <li><strong>Consistency Models Made Easy</strong><br>
      Zhengyang Geng, Ashwini Pokle, <b>Weijian Luo</b>, Justin Lin, J Zico Kolter<br>
      <em>arXiv preprint</em>, arXiv:2406.14548, 2024</li>

  <li><strong>Variational Schrödinger Diffusion Models</strong><br>
      Wei Deng*, <b>Weijian Luo*</b>, Yixin Tan*, Marin Biloš, Yu Chen, Yuriy Nevmyvaka, Ricky TQ Chen<br>
      <em>Forty-first International Conference on Machine Learning.</em> 2024</li>

  <li><strong>SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models</strong><br>
      Shuchen Xue, Mingyang Yi, <b>Weijian Luo</b>, Shifeng Zhang, Jiacheng Sun, Zhengguo Li, Zhiming Ma<br>
      <em>Advances in Neural Information Processing Systems 36</em>, 11, 2024</li>

  <li><strong>Entropy-based Training Methods for Scalable Neural Implicit Samplers</strong><be>
      <b>Weijian Luo</b>, Boya Zhang, Zhihua Zhang<br>
      <em>Advances in Neural Information Processing Systems 36</em>, 1, 2024</li>

  <li><strong>Diff-instruct: A Universal Approach for Transferring Knowledge from Pre-trained Diffusion Models</strong><be>
      <b>Weijian Luo</b>, Tianyang Hu, Shifeng Zhang, Jiacheng Sun, Zhengguo Li, Zhihua Zhang<br>
      <em>Advances in Neural Information Processing Systems 36</em>, 45, 2024</li>

  <li><strong>Enhancing Adversarial Robustness via Score-based Optimization</strong><br>
      Boya Zhang, <b>Weijian Luo</b>, Zhihua Zhang<br>
      <em>Advances in Neural Information Processing Systems 36</em>, 51810-51829, 2023</li>

  <li><strong>Training Energy-Based Models with Diffusion Contrastive Divergences</strong><be>
      <b>Weijian Luo</b>, Hao Jiang, Tianyang Hu, Jiacheng Sun, Zhengguo Li, Zhihua Zhang<br>
      <em>arXiv preprint</em>, arXiv:2307.01668, 2023</li>

  <li><strong>A Comprehensive Survey on Knowledge Distillation of Diffusion Models</strong><be>
      <b>Weijian Luo</b><br>
      <em>arXiv preprint</em>, arXiv:2304.04262, 2023</li>

  <li><strong>A Lipschitz Bandits Approach for Continuous Hyperparameter Optimization</strong><br>
      Yasong Feng, <b>Weijian Luo</b>, Yiming Huang, Tianyu Wang<br>
      <em>arXiv preprint</em>, arXiv:2302.01539, 2023</li>

  <li><strong>Data Prediction Denoising Models: The Pupil Outdoes the Master</strong><br>
      Weijian Luo, Zhihua Zhang</li>
</ul>
 -->
      
<!-- <p><strong>Recent Manuscripts and Publications:</strong> </p>
 -->
<!-- <p>(1) Maximum likelihood learning of deep generative models.</p>
<ul>
    <li>Diffusion recovery likelihood of EBMs <a href="https://arxiv.org/pdf/2012.08125.pdf" target="\_blank">(Gao et al., ICLR 2021)</a>. </li>
  <li>Multi-grid learning of EBMs <a href="https://arxiv.org/pdf/1709.08868.pdf" target="\_blank">(Gao et al., CVPR 2018)</a>. </li>
  <li>Spatial-temporal top-down models <a href="http://www.stat.ucla.edu/~jxie/MotionBasedGenerator/MotionBasedGenerator_file/doc/MotionBasedGenerator.pdf" target="\_blank">(Xie*, Gao*, et al., AAAI 2020)</a>, <a href="http://www.stat.ucla.edu/~jxie/DynamicGenerator/DynamicGenerator_file/doc/DynamicGenerator.pdf" target="\_blank">(Xie*, Gao*, et al., AAAI 2019)</a>. </li>
</ul> -->

<!-- <p>(2) Joint learning of various models.</p>
<ul>
  <li>Contrastive learning of EBMs with flow-based models <a href="https://arxiv.org/pdf/1912.00589.pdf" target="\_blank">(Gao et al., CVPR 2020)</a>. </li>
  <li>Mixing MCMC of EBMs with flow-based models as backbones <a href="https://arxiv.org/pdf/2006.06897.pdf">(Nijkamp*, Gao*, et al., arXiv 2020)</a>.</li>
  <li>Cooperative learning of EBMs with top-down models <a href="http://www.stat.ucla.edu/~jxie/CoopNets/CoopNets_files/doc/CoopNets_PAMI.pdf" target="\_blank">(Xie et al., AAAI 2019 & TPAMI)</a>.</li>
</ul>

<p>(3) Representational models with implications in neuroscience.</p>
<ul>
  <li>Representational models of grid cells <a href="https://arxiv.org/pdf/2006.10259.pdf" target="\_blank">(Gao et al., NeurIPS 2021)</a>, <a href="https://openreview.net/pdf?id=Syx0Mh05YQ" target="\_blank">(Gao et al., ICLR 2019)</a> and applications in 3D vision <a href="https://arxiv.org/pdf/2104.01508.pdf" target="\_blank">(Zhu et al., CVPR 2021)</a>. </li>
  <li>Representational models of V1 cells and applications in motion inference <a href="https://arxiv.org/pdf/1902.03871.pdf" target="\_blank">(Gao et al., AAAI 2022)</a>. </li>
</ul> -->
  </article>

</div>

    </div>

    <!-- Footer -->

    

  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-180825462-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-180825462-1');
</script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
