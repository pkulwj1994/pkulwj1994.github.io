
<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Weijian (William) Luo</title>
<meta name="description" content="Weijian Luo's academic website.">

<!-- Open Graph --> 


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="main.css">

<link rel="canonical" href="/">

<!-- Theming-->


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="row ml-1 ml-sm-0">
          <span class="contact-icon text-center">
  <a href="mailto:pkulwj1994@icloud.com"><i class="fas fa-envelope"></i></a>
  <a href="https://scholar.google.com/citations?hl=zh-CN&user=kAYjIR4AAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>  
  <a href="https://github.com/pkulwj1994" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<!--   <a href="https://www.linkedin.com/in/xxx/" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
<!--   <a href="https://twitter.com/xxx" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a> -->
  
  
  
  
</span>

        </div>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="index.html">
              About
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>

          <li class="nav-item ">
              <a class="nav-link" href="publications.html">
                Publications
                
              </a>
          </li>

          <li class="nav-item ">
              <a class="nav-link" href="CV.pdf">
                CV                
              </a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Weijian Luo</span>
    </h1>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="./photos/me_new.png">
      
      
    </div>
    
    <div class="clearfix">
      <p> <strong>Basic Infos:</strong> I am a final year PhD student in Statistics and Generative Modeling in the School of Mathematical Sciences, <a href="http://english.pku.edu.cn">Peking University</a>. I received my M.S. Degree in Applied Statistics from the School of Mathematical Sciences, <a href="http://english.pku.edu.cn">Peking University</a>, and a B.S. degree in Mathematics from <a href="http://en.ustc.edu.cn/">University of Science and Technology of China (USTC)</a>.</p> 
      <p> My research interests focus on constructing <b>large scale foundation generative models</b>, and also scalable approach for preference alignment (post-training) and distillation of <b> one/few-step text-to-image/video/audio generative models</b> (Check out <a href="https://drive.google.com/file/d/1NrhHBKtVcZ8Jf2-I8v_QKz-Xsdvfqof0/view?usp=sharing">my talk</a> on Diff-Instruct Series. Also refer to <a href="https://arxiv.org/abs/2304.04262">Diffusion Distillation</a>, <a href="https://arxiv.org/abs/2305.18455">Diff-Instruct</a>, <a href="https://arxiv.org/abs/2410.16794">Score-implicit Matching</a>, <a href="https://arxiv.org/abs/2410.18881">Diff-Instruct++</a>, <a href="https://arxiv.org/abs/2410.20898">Diff-Instruct*</a> for details). I am also interested in <b>large vision-language foundation models</b>.</p>
      <p> I work closely with Professor <strong><a href="https://zicokolter.com/" target="_blank">J. Zico Kolter</a></strong>, who is the Director of the Machine Learning Department of the school of Computer Science of Carnegie Mellon University (CMU). I am also invited by Professor <strong><a href="http://maple-lab.net/gqi/" target="_blank">Guo-jun Qi</a></strong> as a Senior Academic Consultant for the <a href="http://maple-lab.net/" target="_blank">MAPLE</a> lab of Westlake University.</p>  
      <p> <strong>Academic Service:</strong>I am invited as a reviewer for academic journals including Nature Communications <a href="https://www.nature.com/ncomms/">(NC)</a>, Journal of Machine Learning Research <a href="https://www.jmlr.org/">(JMLR)</a>, IEEE Transactions on Image Processing <a href="https://signalprocessingsociety.org/publications-resources/ieee-transactions-image-processing">(TIP)</a>, IEEE Transactions on Neural Networks and Learning Systems <a href="https://cis.ieee.org/publications/t-neural-networks-and-learning-systems">(TNNLS)</a>, and Pattern Recognition <a href="https://www.sciencedirect.com/journal/pattern-recognition">(PR)</a>. I also review for top AI Conferences including NeurIPS, ICML, ICLR, CVPR, AISTATS, UAI, ACM-MM, etc;</p>
      <p> <strong>Interns:</strong> Due to limited capacity, I only advise <strong>2-3 casual research interns</strong>. If junior students want to apply for the internship with me, please get in touch with my email.</p>
      <p> <strong>Contact:</strong> <span style="font-family:'Lucida Console', monospace">pkulwj1994 at icloud dot com</span></p>

<p><strong>Selected Talks:</strong></p>
<ul>
<li> <strong>Google Deepmind Research</strong> invited me to deliver a talk in 12th Nov, 2024 on one-step cross-modality generative models. Please check out the slides through <a href="https://drive.google.com/file/d/1NrhHBKtVcZ8Jf2-I8v_QKz-Xsdvfqof0/view?usp=sharing">A Path to Human-preferred One-step Text-to-image Generative Models</a>.
</li>

<li>Research Talk @ Genmo AI, Online, 3rd Jan, 2025: RLHF for Text-to-image Models and Beyond.
</li>

<li>Invited Talk @ Biomedical Engineering lab, Peking University, 25th Oct, 2024: Recent Progress on Diffusion Distillations.
</li>

<li>Invited Talk @ MAPLE lab, Westlake University, 20th Oct, 2024: Efficient Generative Models.
</li>
  
</ul>
      
      
<p><strong>News:</strong></p>

<ul>

  <li><strong>5th Dec 2024: </strong> One pre-print is public on Arxiv.<br>
    <b>Self-Guidance: Boosting Flow and Diffusion Generation on Their Own</b> <a href="https://arxiv.org/abs/2412.05827" target="\_blank">(Li et al., 2024)</a>.<br>
    <em> <b>Self-guidance</b> can improve human hands and bodies of images generated by diffusion or flow models.</em>
  </li>

  <li><strong>1st Dec 2024: </strong> One pre-print is public on Arxiv.<br>
    <b>Schedule On the Fly: Diffusion Time Prediction for Faster and Better Image Generation</b> <a href="https://arxiv.org/abs/2412.01243" target="\_blank">(Ye et al., 2024)</a>.<br>
    <em> We introduced an approach for training variable time-schedule diffusion models using reinforcement learning.</em>
  </li>

  <li><strong>21st Nov 2024: </strong> One paper accepted by Transactions on Machine Learning Research (<b>TMLR</b>).<br>
    <b>Diff-Instruct++: Training One-step Text-to-image Generator Model to Align with Human Preferences</b> <a href="https://arxiv.org/abs/2410.18881" target="\_blank">(Luo, 2024)</a>.<br>
    <em> <b>Diff-Instruct++</b> is the first work on preference alignment of one-step text-to-image generative models, opening the preference alignment with the distillation of diffusion and flow models.</em>
  </li>
  
  <li><strong>12th Nov 2024:</strong> Delivered an invited talk at the <strong>Google Deepmind Diffusion Reading Group</strong> titiled <strong>A Path to Human-preferred One-step Text-to-image Generative Models</strong>. Check the <a href="https://drive.google.com/file/d/1NrhHBKtVcZ8Jf2-I8v_QKz-Xsdvfqof0/view?usp=sharing"><strong>[Slides]</strong></a> here.
  </li>

  <li><strong>30th Oct 2024:</strong> Be invited to give an (internal) online academic talk in the <strong>Google Deepmind research</strong> team on 12th Nov. The talk title is <strong>One-step Text-to-image Generative Models: from Diffusion Distillation to Human-preference Alignment</strong>. In this talk, I will share some exciting progress in improving human preferences for one-step and few-step text-to-image generative models through the lens of Reinforcement Learning using Human Feedback (RLHF). Readers can refer to <a href="https://arxiv.org/abs/2410.18881" target="\_blank">Diff-Insruct++</a> and <a href="https://arxiv.org/abs/2410.20898" target="\_blank">Diff-Insruct*</a> for technical details. 
  </li>
  
  <li><strong>25th Oct 2024:</strong> An invited talk delivered at the Biomedical Engineering lab led by <a href="http://users.cms.caltech.edu/~hesun/">Dr. Sun</a> at Peking University, Beijing, China. The talk is on <strong>Recent Progresses on Diffusion Distillation</strong>.
  </li>
  
  <li><strong>20th Oct 2024:</strong> Had an academic visit to MAPLE lab led by <a href="https://www.westlake.edu.cn/faculty/guojun-qi.html" target="\_blank">Dr. Qi</a> in Westlake University, Hangzhou, China. Delivered a talk on <strong>Efficient Generative Models</strong> to lab members.
  </li>

  <li><strong>18th Oct 2024:</strong> one reprint released on Arxiv.<br>
    <b>One-step Flow Matching Generators</b> <a href="https://arxiv.org/abs/2410.19310" target="\_blank">(Huang et al., 2024)</a>.<br>
    <em>We introduce a novel method to distill the flow-matching-based Stable Diffusion 3 model into strong one-step generators.</em>
  </li>

  <li><strong>18th Oct 2024:</strong> one reprint released on Arxiv.<br>
    <b>Diff-Instruct*: Towards Human-Preferred One-step Text-to-image Generative Models</b> <a href="https://arxiv.org/abs/2410.20898" target="\_blank">(Luo et al., 2024)</a>.<br>
    <em>This paper introduces the <b>Diff-Instruct*</b>, a novel approach to train human-preferred large-scale one-step text-to-image generative models through the lens of online RLHF with general score-based constraints. The resulting one-step 0.6B DiT-DI* model achieves a SoTA <a href="https://github.com/tgxs002/HPSv2" target="\_blank">HPSv2.0</a> score of <b>28.70</b>.</em>
  </li>

  <li><strong>17th Oct 2024:</strong> one reprint released on Arxiv.<br>
    <b>Diff-Instruct++: Training One-step Text-to-image Generator Model to Align with Human Preferences</b> <a href="https://arxiv.org/abs/2410.18881" target="\_blank">(Luo, 2024)</a>.<br>
    <em>This paper introduces the <b>Diff-Instruct++</b>, the first attempt at human preference alignment of large-scale one-step text-to-image generative models. The aligned one-step 0.6B DiT-DI++ model achieves a leading <a href="https://github.com/tgxs002/HPSv2" target="\_blank">HPSv2.0</a> score of <b>28.48</b>.</em>
  </li>
  
  <li><strong>14th Oct 2024:</strong>I passed the PhD defense in 14th Oct in <a href="http://english.pku.edu.cn">Peking University</a>. I feel humbled and grateful to be loved and helped by great advisors, family, and awesome friends.</li>
  
  <li><strong>26th Sep 2024:</strong> one paper accepted by <b>NeurIPS 2024</b>.<br>
    <b>One-step Diffusion Distillation Through Score Implicit Matching</b> <a href="https://arxiv.org/abs/2410.16794" target="\_blank">(Luo et al., NeurIPS 2024)</a>.<br>
    <em>We introduce the score implicit matching, a novel one-step diffusion distillation approach with an amazing one-step text-to-image generative model. Appreciation to Prof. Zico Kolter and Prof. Guojun Qi.</em>
  </li>

  <li><strong>20th Jun 2024:</strong> one preprint released on <b>arXiv</b>.<br>
      <b>Consistency Models Made Easy</b> <a href="https://arxiv.org/abs/2406.14548" target="_blank">(Geng et al., 2024)</a>.<br>
      <em>We introduce a set of practical techniques for efficient training of consistency models, together with a comprehensive study on the Scaling Law of consistency models.</em>
  </li>

  <li><strong>24th Apr 2024:</strong> one paper accepted by <b>ICML 2024</b>.<br>
      <b>Variational Schrödinger Diffusion Models</b> <a href="https://openreview.net/forum?id=kRv0WPJd00" target="_blank">(Deng et al., ICML 2024)</a>.<br>
      <em>We introduce an efficient simulation-free Schrödinger diffusion model, with wide applications for image and time-series generation. Congratulations to Yixin and Dr. Deng.</em>
  </li>

  <li><strong>26th Sep 2023:</strong> one paper accepted by <b>NeurIPS 2023</b>.<br>
      <b>Diff-instruct: A Universal Approach for Transferring Knowledge from Pre-trained Diffusion Models</b> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/f115f619b62833aadc5acb058975b0e6-Abstract-Conference.html" target="_blank">(Luo et al., NeurIPS 2023)</a>.<br>
      <em>Diff-Instruct is a one-step diffusion distillation approach through the lens of distribution matching, with applications on text-to-3D generation and improving GAN generators.</em>
  </li>

  <li><strong>26th Sep 2023:</strong> one paper accepted by <b>NeurIPS 2023</b>.<br>
      <b>Entropy-based Training Methods for Scalable Neural Implicit Samplers</b> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/1646e34971facbcda3727d1dc28ab635-Abstract-Conference.html" target="_blank">(Luo et al., NeurIPS 2023)</a>.<br>
      <em>We introduced two interesting training approaches for neural implicit samplers termed KL and Fisher training.</em>
  </li>

  <li><strong>26th Sep 2023:</strong> one paper accepted by <b>NeurIPS 2023</b>.<br>
      <b>SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models</b> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/f4a6806490d31216a3ba667eb240c897-Abstract-Conference.html" target="_blank">(Xue et al., NeurIPS 2023)</a>.<br>
      <em>We introduced a novel diffusion sampler based on the Stochastic Adam theory, integrated for PixelArt-alpha diffusion models.</em>
  </li>

  <li><strong>26th Sep 2023:</strong> one paper accepted by <b>NeurIPS 2023</b>.<br>
      <b>Enhancing Adversarial Robustness via Score-based Optimization</b> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/a2e707354da36956945dbb288efe82b3-Abstract-Conference.html" target="_blank">(Zhang et al., NeurIPS 2023)</a>.<br>
      <em>We introduced a novel optimization-based adversarial defense based on pre-trained diffusion models.</em>
  </li>

  <li><strong>9th Apr 2023:</strong> one paper released on <b>arXiv</b>.<br>
      <b>A Comprehensive Survey on Knowledge Distillation of Diffusion Models</b> <a href="https://arxiv.org/abs/2304.04262" target="_blank">(Luo, 2023)</a>.<br>
      <em>The first survey on diffusion distillation and knowledge transferring of diffusion models.</em>
  </li>
</ul>


<p><strong>Friends with whom I have worked on projects:</strong></p>

<ul>
  <li><strong><a href="https://zicokolter.com/" target="_blank">J. Zico Kolter</a></strong>, Professor, Director of the Machine Learning Department, Carnegie Mellon University (CMU).<br>
  </li>
  <li><strong><a href="http://maple-lab.net/gqi/" target="_blank">Guo-jun Qi</a></strong>, Professor, IEEE Fellow, Director of MAPLE Lab of Westlake University.<br>
  </li>
  <li><strong><a href="https://www.weideng.org/" target="_blank">Wei Deng</a></strong>, PhD, Research Scientist at Morgan Stanley, New York.<br>
  </li>
  <li><strong><a href="https://rtqichen.github.io/" target="_blank">Ricky Tian Qi Chen</a></strong>, PhD, Research Scientist at Meta Fundamental AI Research (FAIR), New York.<br>
  </li>
  <li><strong><a href="https://www.linkedin.com/in/sethforsgren/" target="_blank">Seth Forsgren</a></strong>, BS from Princeton, CEO and the founder of <a href="https://www.riffusion.com/" target="_blank">Riffusion AI</a>, San Francisco.<br>
  </li>
  <li><strong><a href="https://www.haykmartiros.com/" target="_blank">Hayk Martiros</a></strong>, MS from Stanford, CTO and the co-founder of <a href="https://www.riffusion.com/" target="_blank">Riffusion AI</a>, previous technical VP of <a href="https://www.skydio.com/" target="_blank">Skydio</a>.<br>
  </li>
  <li><strong><a href="" target="_blank">He Sun</a></strong>, PhD, Assistant Professor at <a href="https://english.pku.edu.cn/" target="_blank">Peking University</a>.<br>
  </li>
  <li><strong><a href="" target="_blank">Debing Zhang</a></strong>, PhD, Director of AGI team of Xiaohongshu.<br>
  </li>
  <li><strong><a href="" target="_blank">Tianyang Hu</a></strong>, PhD, Incoming Assistant Professor at the Chinese University of Hong Kong, Shenzhen (<a href="https://sds.cuhk.edu.cn/en" target="_blank">CUHK-Shenzhen</a>).<br>
  </li>
  
  
<p><strong>Past advised Students:</strong></p>
  <li><strong><a href="" target="_blank">Weimin Bai</a></strong>, PhD student at Peking University.<br>
  <li><strong><a href="" target="_blank">Yubo Li</a></strong>, B.S. student at Tsinghua University, and incoming PhD student at Peking University.<br>
  <li><strong><a href="" target="_blank">Yifei Wang</a></strong>, B.S. student at Peking University.<br>
  <li><strong><a href="" target="_blank">Zhuo Le</a></strong>, incoming CS PhD student of <a href="https://mmlab.ie.cuhk.edu.hk/index.html" target="_blank">MMLab</a> at the Chinese University of Hong Kong.<br>
  <li><strong><a href="" target="_blank">Zemin Huang</a></strong>, CS PhD student of Joint PhD Program of Zhejiang University and Westlake University.<br>
  <li><strong><a href="" target="_blank">Tiancheng Li</a></strong>, CS PhD student of Joint PhD Program of Zhejiang University and Westlake University.<br>

</ul>
  
  
<!--       I am in the job market for the position of AIGC experts! </p>        
 -->
      
<!-- <p><strong> Research Areas:</strong> </p>
<p>Generative Modeling, Diffusion Models, Energy-Based Models, Statistical Sampling</p>

<p><strong> Lectures and Talks:</strong> </p>
<p><a href="http://www.cmstatistics.org/CMStatistics2022/index.php">Diffusion Contrastive Divergence@CMStatistics 2022 hybrid conference</a></p>      
<p><a href="https://www.math.pku.edu.cn/kxyj/xsbg/tlb/informationsciences/134567.htm">解读AI技术的应用进展</a></p>
<p><a href="https://www.math.pku.edu.cn/kxyj/xsbg/tlb/informationsciences/142129.htm">An introduction to Diffusion Probabilistic Models (DPM)</a></p>
<p><a href="https://www.math.pku.edu.cn/kxyj/xsbg/tlb/informationsciences/131427.htm">Recent Progress on Generative Modeling</a></p>
       -->
      
<!-- <p><strong> Sevices:</strong> </p> -->
<!-- <p>Reviewers: ICML, ICLR, AISTAT, UAI, AAAI.</p> -->
<!-- <p><strong> Softwares or Toolkits:</strong> </p> -->

<!-- <p><strong>Selected Publications (* indicates equal contribution or corresponding author):</strong></p>
<ul>

  <li><strong>Denoising Fisher Training For Neural Implicit Samplers</strong><be>
      <b>Weijian Luo</b>, Wei Deng<br>
      <em>preprint</em>, 2024</li>

  <li><strong>One-step Flow Matching Generators</strong><br>
      Zemin Huang, Zhengyang Geng, <b>Weijian Luo*</b>, Guo-Jun Qi<br>
      <em>preprint</em>, 2024</li>

  <li><strong>Diff-Instruct*: Towards Human-Preferred One-step Text-to-image Generative Models</strong><be>
      <b>Weijian Luo</b>, Colin zhang, Debing Zhang, Zhengyang Geng<br>
      <em>preprint</em>, 2024</li>
  
  <li><strong>One-Step Diffusion Distillation through Score Implicit Matching</strong><be>
      <b>Weijian Luo</b>, Zemin Huang, Zhengyang Geng, J Zico Kolter, Guo-Jun Qi<br>
      <em>Advances in Neural Information Processing Systems 37</em>, 2024</li>
  
  <li><strong>Diff-Instruct++: Training One-step Text-to-image Generator Model to Align with Human Preferences</strong><br>
      <b>Weijian Luo</b><br>
      <em>preprint</em>, 2024</li>
  
  <li><strong>Integrating Amortized Inference with Diffusion Models for Learning Clean Distribution from Corrupted Images</strong><br>
      Yifei Wang, Weimin Bai, <b>Weijian Luo</b>, Wenzheng Chen, He Sun<br>
      <em>arXiv preprint</em>, arXiv:2407.11162, 2024</li>

  <li><strong>Consistency Models Made Easy</strong><br>
      Zhengyang Geng, Ashwini Pokle, <b>Weijian Luo</b>, Justin Lin, J Zico Kolter<br>
      <em>arXiv preprint</em>, arXiv:2406.14548, 2024</li>

  <li><strong>Variational Schrödinger Diffusion Models</strong><br>
      Wei Deng*, <b>Weijian Luo*</b>, Yixin Tan*, Marin Biloš, Yu Chen, Yuriy Nevmyvaka, Ricky TQ Chen<br>
      <em>Forty-first International Conference on Machine Learning.</em> 2024</li>

  <li><strong>SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models</strong><br>
      Shuchen Xue, Mingyang Yi, <b>Weijian Luo</b>, Shifeng Zhang, Jiacheng Sun, Zhengguo Li, Zhiming Ma<br>
      <em>Advances in Neural Information Processing Systems 36</em>, 11, 2024</li>

  <li><strong>Entropy-based Training Methods for Scalable Neural Implicit Samplers</strong><be>
      <b>Weijian Luo</b>, Boya Zhang, Zhihua Zhang<br>
      <em>Advances in Neural Information Processing Systems 36</em>, 1, 2024</li>

  <li><strong>Diff-instruct: A Universal Approach for Transferring Knowledge from Pre-trained Diffusion Models</strong><be>
      <b>Weijian Luo</b>, Tianyang Hu, Shifeng Zhang, Jiacheng Sun, Zhengguo Li, Zhihua Zhang<br>
      <em>Advances in Neural Information Processing Systems 36</em>, 45, 2024</li>

  <li><strong>Enhancing Adversarial Robustness via Score-based Optimization</strong><br>
      Boya Zhang, <b>Weijian Luo</b>, Zhihua Zhang<br>
      <em>Advances in Neural Information Processing Systems 36</em>, 51810-51829, 2023</li>

  <li><strong>Training Energy-Based Models with Diffusion Contrastive Divergences</strong><be>
      <b>Weijian Luo</b>, Hao Jiang, Tianyang Hu, Jiacheng Sun, Zhengguo Li, Zhihua Zhang<br>
      <em>arXiv preprint</em>, arXiv:2307.01668, 2023</li>

  <li><strong>A Comprehensive Survey on Knowledge Distillation of Diffusion Models</strong><be>
      <b>Weijian Luo</b><br>
      <em>arXiv preprint</em>, arXiv:2304.04262, 2023</li>

  <li><strong>A Lipschitz Bandits Approach for Continuous Hyperparameter Optimization</strong><br>
      Yasong Feng, <b>Weijian Luo</b>, Yiming Huang, Tianyu Wang<br>
      <em>arXiv preprint</em>, arXiv:2302.01539, 2023</li>

  <li><strong>Data Prediction Denoising Models: The Pupil Outdoes the Master</strong><br>
      Weijian Luo, Zhihua Zhang</li>
</ul>
 -->
      
<!-- <p><strong>Recent Manuscripts and Publications:</strong> </p>
 -->
<!-- <p>(1) Maximum likelihood learning of deep generative models.</p>
<ul>
    <li>Diffusion recovery likelihood of EBMs <a href="https://arxiv.org/pdf/2012.08125.pdf" target="\_blank">(Gao et al., ICLR 2021)</a>. </li>
  <li>Multi-grid learning of EBMs <a href="https://arxiv.org/pdf/1709.08868.pdf" target="\_blank">(Gao et al., CVPR 2018)</a>. </li>
  <li>Spatial-temporal top-down models <a href="http://www.stat.ucla.edu/~jxie/MotionBasedGenerator/MotionBasedGenerator_file/doc/MotionBasedGenerator.pdf" target="\_blank">(Xie*, Gao*, et al., AAAI 2020)</a>, <a href="http://www.stat.ucla.edu/~jxie/DynamicGenerator/DynamicGenerator_file/doc/DynamicGenerator.pdf" target="\_blank">(Xie*, Gao*, et al., AAAI 2019)</a>. </li>
</ul> -->

<!-- <p>(2) Joint learning of various models.</p>
<ul>
  <li>Contrastive learning of EBMs with flow-based models <a href="https://arxiv.org/pdf/1912.00589.pdf" target="\_blank">(Gao et al., CVPR 2020)</a>. </li>
  <li>Mixing MCMC of EBMs with flow-based models as backbones <a href="https://arxiv.org/pdf/2006.06897.pdf">(Nijkamp*, Gao*, et al., arXiv 2020)</a>.</li>
  <li>Cooperative learning of EBMs with top-down models <a href="http://www.stat.ucla.edu/~jxie/CoopNets/CoopNets_files/doc/CoopNets_PAMI.pdf" target="\_blank">(Xie et al., AAAI 2019 & TPAMI)</a>.</li>
</ul>

<p>(3) Representational models with implications in neuroscience.</p>
<ul>
  <li>Representational models of grid cells <a href="https://arxiv.org/pdf/2006.10259.pdf" target="\_blank">(Gao et al., NeurIPS 2021)</a>, <a href="https://openreview.net/pdf?id=Syx0Mh05YQ" target="\_blank">(Gao et al., ICLR 2019)</a> and applications in 3D vision <a href="https://arxiv.org/pdf/2104.01508.pdf" target="\_blank">(Zhu et al., CVPR 2021)</a>. </li>
  <li>Representational models of V1 cells and applications in motion inference <a href="https://arxiv.org/pdf/1902.03871.pdf" target="\_blank">(Gao et al., AAAI 2022)</a>. </li>
</ul> -->
  </article>

</div>

    </div>

    <!-- Footer -->

    

  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-180825462-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-180825462-1');
</script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
